[
  {
    "objectID": "tutorials/saving/topic2.html",
    "href": "tutorials/saving/topic2.html",
    "title": "Second Topic",
    "section": "",
    "text": "Duis ornare ex ac iaculis pretium. Maecenas sagittis odio id erat pharetra, sit amet consectetur quam sollicitudin. Vivamus pharetra quam purus, nec sagittis risus pretium at. Nullam feugiat, turpis ac accumsan interdum, sem tellus blandit neque, id vulputate diam quam semper nisl. Donec sit amet enim at neque porttitor aliquet. Phasellus facilisis nulla eget placerat eleifend. Vestibulum non egestas eros, eget lobortis ipsum. Nulla rutrum massa eget enim aliquam, id porttitor erat luctus. Nunc sagittis quis eros eu sagittis. Pellentesque dictum, erat at pellentesque sollicitudin, justo augue pulvinar metus, quis rutrum est mi nec felis. Vestibulum efficitur mi lorem, at elementum purus tincidunt a. Aliquam finibus enim magna, vitae pellentesque erat faucibus at. Nulla mauris tellus, imperdiet id lobortis et, dignissim condimentum ipsum. Morbi nulla orci, varius at aliquet sed, facilisis id tortor. Donec ut urna nisi.\nAenean placerat luctus tortor vitae molestie. Nulla at aliquet nulla. Sed efficitur tellus orci, sed fringilla lectus laoreet eget. Vivamus maximus quam sit amet arcu dignissim, sed accumsan massa ullamcorper. Sed iaculis tincidunt feugiat. Nulla in est at nunc ultricies dictum ut vitae nunc. Aenean convallis vel diam at malesuada. Suspendisse arcu libero, vehicula tempus ultrices a, placerat sit amet tortor. Sed dictum id nulla commodo mattis. Aliquam mollis, nunc eu tristique faucibus, purus lacus tincidunt nulla, ac pretium lorem nunc ut enim. Curabitur eget mattis nisl, vitae sodales augue. Nam felis massa, bibendum sit amet nulla vel, vulputate rutrum lacus. Aenean convallis odio pharetra nulla mattis consequat.\n\n\n\n Back to top"
  },
  {
    "objectID": "tutorials/saving/index.html",
    "href": "tutorials/saving/index.html",
    "title": "Second Tutorial",
    "section": "",
    "text": "This is the landing page for the second tutorial."
  },
  {
    "objectID": "tutorials/saving/index.html#blah",
    "href": "tutorials/saving/index.html#blah",
    "title": "Second Tutorial",
    "section": "Blah",
    "text": "Blah\nEtiam non efficitur urna, quis elementum nisi. Mauris posuere a augue vel gravida. Praesent luctus erat et ex iaculis interdum. Nulla vestibulum quam ac nunc consequat vulputate. Nullam iaculis lobortis sem sit amet fringilla. Aliquam semper, metus ut blandit semper, nulla velit fermentum sapien, fermentum ultrices dolor sapien sed leo. Vestibulum molestie faucibus magna, at feugiat nulla ullamcorper a. Aliquam erat volutpat. Praesent scelerisque magna a justo maximus, sit amet suscipit mauris tempor. Nulla nec dolor eget ipsum pellentesque lobortis a in ipsum. Morbi turpis turpis, fringilla a eleifend maximus, viverra nec neque. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos.\n\nBlah, Blah\nMaecenas turpis velit, ultricies non elementum vel, luctus nec nunc. Nulla a diam interdum, faucibus sapien viverra, finibus metus. Donec non tortor diam. In ut elit aliquet, bibendum sem et, aliquam tortor. Donec congue, sem at rhoncus ultrices, nunc augue cursus erat, quis porttitor mauris libero ut ex. Nullam quis leo urna. Donec faucibus ligula eget pellentesque interdum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean rhoncus interdum erat ut ultricies. Aenean tempus ex non elit suscipit, quis dignissim enim efficitur. Proin laoreet enim massa, vitae laoreet nulla mollis quis.\nVestibulum ultrices, tortor at mattis porta, odio nisi rutrum nulla, sit amet tincidunt eros quam facilisis tellus. Fusce eleifend lectus in elementum lacinia. Nam auctor nunc in massa ullamcorper, sit amet auctor ante accumsan. Nam ut varius metus. Curabitur eget tristique leo. Cras finibus euismod erat eget elementum. Integer vel placerat ex. Ut id eros quis lectus lacinia venenatis hendrerit vel ante."
  },
  {
    "objectID": "tutorials/loading/r_data.html",
    "href": "tutorials/loading/r_data.html",
    "title": "Native Data Formats",
    "section": "",
    "text": "R provides two native data formats: RData and RDS.",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Native Data Formats"
    ]
  },
  {
    "objectID": "tutorials/loading/r_data.html#rdata-files",
    "href": "tutorials/loading/r_data.html#rdata-files",
    "title": "Native Data Formats",
    "section": "RData Files",
    "text": "RData Files\nAlthough we can certain store datasets as RData files, it’s a bit misleading to characterize the RData format as a tool for storing datasets. RData files are actually compressed snapshots of an entire R environment. So, when we “load” an RData file, we’re not really loading a single dataset; rather, we’re “restoring” the contents of the environment stored in the file. Of course, the environment we restore may contain only a single datasets, in which case the end result will be functional equivalent to loading that dataset. It’s worth remembering, though, that the RData format is a more general tool than we need for this job.\nWe use the load() function to load RData files. In the following code chunk, we load the \"boys.RData\" object. This file contains only a single data frame called boys.\n\ndataDir &lt;- \"data\"\n\n# List the contents of the current environment\nls()\n\n[1] \"dataDir\"\n\n# Load the objects stored in 'boys.RData'\nload(here::here(dataDir, \"boys.RData\"))\n\n# Now we have a new data frame in our environment\nls()\n\n[1] \"boys\"    \"dataDir\"\n\nhead(boys)\n\n     age  hgt   wgt   bmi   hc  gen  phb tv   reg\n3  0.035 50.1 3.650 14.54 33.7 &lt;NA&gt; &lt;NA&gt; NA south\n4  0.038 53.5 3.370 11.77 35.0 &lt;NA&gt; &lt;NA&gt; NA south\n18 0.057 50.0 3.140 12.56 35.2 &lt;NA&gt; &lt;NA&gt; NA south\n23 0.060 54.5 4.270 14.37 36.7 &lt;NA&gt; &lt;NA&gt; NA south\n28 0.062 57.5 5.030 15.21 37.3 &lt;NA&gt; &lt;NA&gt; NA south\n36 0.068 55.5 4.655 15.11 37.0 &lt;NA&gt; &lt;NA&gt; NA south\n\n\nNotice that we don’t assign the return value of load() to an object. When we run load(), we simply add all the objects stored therein to our current environment. Hence, RData files are best suited to capturing an instantaneous snapshot of your current R session so that you can exactly restore the current state of your environment sometime in the future.\nIn the following code chunk, we use an RData object to restore the snapshot of a previous R session.\n\n# The environment contains only the objects we loaded in the last example\nls()\n\n[1] \"boys\"    \"dataDir\"\n\n# Load the objects stored in 'snapshot.RData'\nload(here::here(dataDir, \"snapshot.RData\"))\n\n# Now, we've added several new objects to our session\nls()\n\n[1] \"attitude\" \"boys\"     \"dataDir\"  \"iris\"     \"out\"      \"p1\"      \n\n\nAfter we restore the objects stored in “snapshot.RData”, we add two new datasets, iris and attitude, but we also restore a set of regression model results, out, and a ggplot object, p1.\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nstr(attitude)\n\n'data.frame':   30 obs. of  7 variables:\n $ rating    : num  43 63 71 61 81 43 58 71 72 67 ...\n $ complaints: num  51 64 70 63 78 55 67 75 82 61 ...\n $ privileges: num  30 51 68 45 56 49 42 50 72 45 ...\n $ learning  : num  39 54 69 47 66 44 56 55 67 47 ...\n $ raises    : num  61 63 76 54 71 54 66 70 71 62 ...\n $ critical  : num  92 73 86 84 83 49 68 66 83 80 ...\n $ advance   : num  45 47 48 35 47 34 35 41 31 41 ...\n\nsummary(out)\n\n\nCall:\nlm(formula = Petal.Width ~ Petal.Length + Species, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.63706 -0.07779 -0.01218  0.09829  0.47814 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -0.09083    0.05639  -1.611    0.109    \nPetal.Length       0.23039    0.03443   6.691 4.41e-10 ***\nSpeciesversicolor  0.43537    0.10282   4.234 4.04e-05 ***\nSpeciesvirginica   0.83771    0.14533   5.764 4.71e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1796 on 146 degrees of freedom\nMultiple R-squared:  0.9456,    Adjusted R-squared:  0.9445 \nF-statistic: 845.5 on 3 and 146 DF,  p-value: &lt; 2.2e-16\n\nprint(p1)\n\n\n\n\n\n\n\n\nWe could now pick up with our previous analysis exactly where we left off when we created “snapshot.RData”.",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Native Data Formats"
    ]
  },
  {
    "objectID": "tutorials/loading/r_data.html#rds-files",
    "href": "tutorials/loading/r_data.html#rds-files",
    "title": "Native Data Formats",
    "section": "RDS Files",
    "text": "RDS Files\nRData files are much better for the kind of “back-up and restore” operations that we see in the preceding example than they are for storing individual datasets. Fortunately, R has a second native data format that is ideally suited for storing datasets. RDS files are specifically designed to store single R objects like the data frames we typically use to hold datasets. We use the readRDS() function to load RDS files.\n\ntitanic &lt;- readRDS(here::here(dataDir, \"titanic.rds\"))\nstr(titanic)\n\n'data.frame':   887 obs. of  8 variables:\n $ survived        : Factor w/ 2 levels \"no\",\"yes\": 1 2 2 2 1 1 1 1 2 2 ...\n $ class           : Factor w/ 3 levels \"1st\",\"2nd\",\"3rd\": 3 1 3 1 3 3 1 3 3 2 ...\n $ name            : chr  \"Mr. Owen Harris Braund\" \"Mrs. John Bradley (Florence Briggs Thayer) Cumings\" \"Miss. Laina Heikkinen\" \"Mrs. Jacques Heath (Lily May Peel) Futrelle\" ...\n $ sex             : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 2 2 2 1 1 ...\n $ age             : num  22 38 26 35 35 27 54 2 27 14 ...\n $ siblings_spouses: int  1 1 0 1 0 0 0 3 0 1 ...\n $ parents_children: int  0 0 0 0 0 0 0 1 2 0 ...\n $ fare            : num  7.25 71.28 7.92 53.1 8.05 ...\n\n\nNotice how the readRDS() call follows the same conventions as the other data-ingest functions we’ve covered. Most importantly, readRDS() returns a single R object, and we assign that object to a variable in our environment.\n\n\n\n\n\n\nPractice\n\n\n\n\nLoad the dataset saved as “./data/diabetes.rds”.\nUse the str() function to compare the structure of the dataset you loaded to the diabetes0 object loaded below.\n\nAre there any differences between these two objects? If so, what are the differences?\n\n Interactive Editor Directory Structure Solution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe following dendrogram illustrates the structure of the working directory for this webr session.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\ndiabetes0 &lt;- read.table(here::here(\"data\", \"diabetes.txt\"), header = TRUE, sep = \"\\t\")\ndiabetes1 &lt;- readRDS(here::here(\"data\", \"diabetes.rds\"))\nstr(diabetes0)\n\n'data.frame':   442 obs. of  11 variables:\n $ age     : int  59 48 72 24 50 23 36 66 60 29 ...\n $ bmi     : num  32.1 21.6 30.5 25.3 23 22.6 22 26.2 32.1 30 ...\n $ bp      : num  101 87 93 84 101 89 90 114 83 85 ...\n $ tc      : int  157 183 156 198 192 139 160 255 179 180 ...\n $ ldl     : num  93.2 103.2 93.6 131.4 125.4 ...\n $ hdl     : num  38 70 41 40 52 61 50 56 42 43 ...\n $ tch     : num  4 3 4 5 4 2 3 4.55 4 4 ...\n $ ltg     : num  4.86 3.89 4.67 4.89 4.29 ...\n $ glu     : int  87 69 85 89 80 68 82 92 94 88 ...\n $ progress: int  151 75 141 206 135 97 138 63 110 310 ...\n $ sex     : chr  \"male\" \"female\" \"male\" \"female\" ...\n\nstr(diabetes1)\n\n'data.frame':   442 obs. of  11 variables:\n $ age     : int  59 48 72 24 50 23 36 66 60 29 ...\n $ bmi     : num  32.1 21.6 30.5 25.3 23 22.6 22 26.2 32.1 30 ...\n $ bp      : num  101 87 93 84 101 89 90 114 83 85 ...\n $ tc      : int  157 183 156 198 192 139 160 255 179 180 ...\n $ ldl     : num  93.2 103.2 93.6 131.4 125.4 ...\n $ hdl     : num  38 70 41 40 52 61 50 56 42 43 ...\n $ tch     : num  4 3 4 5 4 2 3 4.55 4 4 ...\n $ ltg     : num  4.86 3.89 4.67 4.89 4.29 ...\n $ glu     : int  87 69 85 89 80 68 82 92 94 88 ...\n $ progress: int  151 75 141 206 135 97 138 63 110 310 ...\n $ sex     : Factor w/ 2 levels \"female\",\"male\": 2 1 2 1 1 1 2 2 2 1 ...\n\n\nThe main difference between these two objects lies in the fact that diabetes1 preserves all the R-specific formatting. Notably, the sex variable is stored as a two-level factor in diabetes1. In diabetes0, on the other hand, sex is a character vector.",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Native Data Formats"
    ]
  },
  {
    "objectID": "tutorials/loading/excel_files.html",
    "href": "tutorials/loading/excel_files.html",
    "title": "Excel Files",
    "section": "",
    "text": "Please enable JavaScript to experience the dynamic code cell content on this page.\nTo wrap up our discussion of data-ingest methods, we’ll consider Microsoft Excel workbooks. Many datasets, especially those shared outside of academia, are stored and distributed as Excel workbooks. Thankfully, when you encounter such datasets, you’ll have no problems loading the data because several R packages allow us to work with Excel workbooks.\nFor quick-and-easy data-ingest from an Excel workbook, the readxl package is a good option. We can load data from an Excel workbook with the readxl::read_excel() function.\n\nlibrary(readxl)\n\ndataDir &lt;- \"data\"\n\ntitanic1 &lt;- read_excel(here::here(dataDir, \"example_data.xlsx\"), sheet = \"titanic\")\nhead(titanic1)\n\n# A tibble: 6 × 8\n  survived class name        sex     age siblings_spouses parents_children  fare\n  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt;\n1 no       3rd   Mr. Owen H… male     22                1                0  7.25\n2 yes      1st   Mrs. John … fema…    38                1                0 71.3 \n3 yes      3rd   Miss. Lain… fema…    26                0                0  7.92\n4 yes      1st   Mrs. Jacqu… fema…    35                1                0 53.1 \n5 no       3rd   Mr. Willia… male     35                0                0  8.05\n6 no       3rd   Mr. James … male     27                0                0  8.46\n\n\nNotice that we need to specify which sheet holds our target data via the sheet argument. If we don’t specify a value for the sheet argument, read_excel() will read from the first sheet in the workbook.\nIf we only need to load data, then readxl will usually suffice, but we won’t be able to save data back to an XLSX workbook with readxl functions. So, if we want to write data back to an Excel workbook, we should consider a using different package. The openxlsx package is a good option.\nThe procedure for reading data with openxlsx is almost identical to what we did with readxl. In this case, we use the openxslx::read.xlsx() function.\n\nlibrary(openxlsx)\n\ntitanic2 &lt;- read.xlsx(here::here(dataDir, \"example_data.xlsx\"), sheet = \"titanic\")\nhead(titanic2)\n\n  survived class                                               name    sex age\n1       no   3rd                             Mr. Owen Harris Braund   male  22\n2      yes   1st Mrs. John Bradley (Florence Briggs Thayer) Cumings female  38\n3      yes   3rd                              Miss. Laina Heikkinen female  26\n4      yes   1st        Mrs. Jacques Heath (Lily May Peel) Futrelle female  35\n5       no   3rd                            Mr. William Henry Allen   male  35\n6       no   3rd                                    Mr. James Moran   male  27\n  siblings_spouses parents_children    fare\n1                1                0  7.2500\n2                1                0 71.2833\n3                0                0  7.9250\n4                1                0 53.1000\n5                0                0  8.0500\n6                0                0  8.4583\n\n\nWhen we compare the two datasets, we see that they return functional equivalent objects. The only notable difference is that readxl::read_excel() returns a tibble while openxlsx::read.xlsx() returns a Base R data frame.\n\nstr(titanic1)\n\ntibble [887 × 8] (S3: tbl_df/tbl/data.frame)\n $ survived        : chr [1:887] \"no\" \"yes\" \"yes\" \"yes\" ...\n $ class           : chr [1:887] \"3rd\" \"1st\" \"3rd\" \"1st\" ...\n $ name            : chr [1:887] \"Mr. Owen Harris Braund\" \"Mrs. John Bradley (Florence Briggs Thayer) Cumings\" \"Miss. Laina Heikkinen\" \"Mrs. Jacques Heath (Lily May Peel) Futrelle\" ...\n $ sex             : chr [1:887] \"male\" \"female\" \"female\" \"female\" ...\n $ age             : num [1:887] 22 38 26 35 35 27 54 2 27 14 ...\n $ siblings_spouses: num [1:887] 1 1 0 1 0 0 0 3 0 1 ...\n $ parents_children: num [1:887] 0 0 0 0 0 0 0 1 2 0 ...\n $ fare            : num [1:887] 7.25 71.28 7.92 53.1 8.05 ...\n\nstr(titanic2)\n\n'data.frame':   887 obs. of  8 variables:\n $ survived        : chr  \"no\" \"yes\" \"yes\" \"yes\" ...\n $ class           : chr  \"3rd\" \"1st\" \"3rd\" \"1st\" ...\n $ name            : chr  \"Mr. Owen Harris Braund\" \"Mrs. John Bradley (Florence Briggs Thayer) Cumings\" \"Miss. Laina Heikkinen\" \"Mrs. Jacques Heath (Lily May Peel) Futrelle\" ...\n $ sex             : chr  \"male\" \"female\" \"female\" \"female\" ...\n $ age             : num  22 38 26 35 35 27 54 2 27 14 ...\n $ siblings_spouses: num  1 1 0 1 0 0 0 3 0 1 ...\n $ parents_children: num  0 0 0 0 0 0 0 1 2 0 ...\n $ fare            : num  7.25 71.28 7.92 53.1 8.05 ...\n\n# Convert 'titanic1' from a tibble to an ordinary data frame\ntitanic1.2 &lt;- as.data.frame(titanic1)\n\n# Are the two objects equivalent?\nall.equal(titanic1.2, titanic2)\n\n[1] TRUE\n\n\n\n\n\n\n\n\nPractice\n\n\n\nUse both readxl::read_excel() and openxlsx::read.xlsx() to load the data from the “diabetes” sheet in the Excel workbook stored as “./data/example_data.xlsx”.\n\n Interactive Editor Directory Structure Solution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe following dendrogram illustrates the structure of the working directory for this webr session.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\ndiabetes1 &lt;- read_excel(here::here(\"data\", \"example_data.xlsx\"),\n                        sheet = \"diabetes\")\nhead(diabetes1)\n\n# A tibble: 6 × 11\n    age   bmi    bp    tc   ldl   hdl   tch   ltg   glu progress sex   \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; \n1    59  32.1   101   157  93.2    38     4  4.86    87      151 male  \n2    48  21.6    87   183 103.     70     3  3.89    69       75 female\n3    72  30.5    93   156  93.6    41     4  4.67    85      141 male  \n4    24  25.3    84   198 131.     40     5  4.89    89      206 female\n5    50  23     101   192 125.     52     4  4.29    80      135 female\n6    23  22.6    89   139  64.8    61     2  4.19    68       97 female\n\ndiabetes2 &lt;- read.xlsx(here::here(\"data\", \"example_data.xlsx\"),\n                      sheet = \"diabetes\")\nhead(diabetes2)\n\n  age  bmi  bp  tc   ldl hdl tch    ltg glu progress    sex\n1  59 32.1 101 157  93.2  38   4 4.8598  87      151   male\n2  48 21.6  87 183 103.2  70   3 3.8918  69       75 female\n3  72 30.5  93 156  93.6  41   4 4.6728  85      141   male\n4  24 25.3  84 198 131.4  40   5 4.8903  89      206 female\n5  50 23.0 101 192 125.4  52   4 4.2905  80      135 female\n6  23 22.6  89 139  64.8  61   2 4.1897  68       97 female\n\n\n\n\n\n\n\n\nLoading Specific Cells\nIn addition to selecting the sheet from which we want to read our dataset, we can also specify the range of cells within that sheet that we want to read. This capability is particularly useful because Excel workbooks are typically organized as interactive spreadsheets that include additional, arbitrarily organized metadata cells and formula cells. These additional cells often violate the regular grid structure that we assume for a rectangular datasets.\nFor example, the following image shows the “exam_results” sheet from the “./data/example_data.xlsx” workbook. This sheet contains an interactive spreadsheet that summarizes the results of a hypothetical exam. Notice how the sheet contains nine leading rows and six trailing rows of metadata surrounding the 31 rows of individual exam results (and column names). If we’re interested in the individual exam results, the extra metadata rows will cause problems.\n\nIf we try to read all the data in this sheet, we get the following results.\n\nres1 &lt;- read_excel(here::here(dataDir, \"example_data.xlsx\"),\n                   sheet = \"exam_results\")\nres1\n\n# A tibble: 45 × 8\n   `Program:`  Dept. Of Underwater Basket Wea…¹ ...3  ...4  `Exam Date:` `45658`\n   &lt;chr&gt;       &lt;chr&gt;                            &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;  \n 1 Instructor: Dr. Foo Bar                      &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;   \n 2 Exam Name:  Advanced Aquatic Lashing Theory  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;   \n 3 &lt;NA&gt;        &lt;NA&gt;                             &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;   \n 4 Score       Percentage                       &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;   \n 5 0           0                                &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;   \n 6 21          55                               &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;   \n 7 40          100                              &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;   \n 8 &lt;NA&gt;        &lt;NA&gt;                             &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;         &lt;NA&gt;   \n 9 ID          First Name                       Last… &lt;NA&gt;  Grade        Version\n10 389472      Aniyah                           Rojas &lt;NA&gt;  5.7          A      \n# ℹ 35 more rows\n# ℹ abbreviated name: ¹​`Dept. Of Underwater Basket Weaving`\n# ℹ 2 more variables: `Batch ID:` &lt;chr&gt;, `314159` &lt;chr&gt;\n\ncolnames(res1)\n\n[1] \"Program:\"                           \"Dept. Of Underwater Basket Weaving\"\n[3] \"...3\"                               \"...4\"                              \n[5] \"Exam Date:\"                         \"45658\"                             \n[7] \"Batch ID:\"                          \"314159\"                            \n\nres2 &lt;- read.xlsx(here::here(dataDir, \"example_data.xlsx\"),\n                  sheet = \"exam_results\")\nres2\n\n              Program: Dept..Of.Underwater.Basket.Weaving         X3        X4\n1          Instructor:                        Dr. Foo Bar       &lt;NA&gt;      &lt;NA&gt;\n2           Exam Name:    Advanced Aquatic Lashing Theory       &lt;NA&gt;      &lt;NA&gt;\n3                Score                         Percentage       &lt;NA&gt;      &lt;NA&gt;\n4                    0                                  0       &lt;NA&gt;      &lt;NA&gt;\n5                   21                                 55       &lt;NA&gt;      &lt;NA&gt;\n6                   40                                100       &lt;NA&gt;      &lt;NA&gt;\n7                   ID                         First Name  Last Name      &lt;NA&gt;\n8               389472                             Aniyah      Rojas      &lt;NA&gt;\n9               915603                              Colin      Logan      &lt;NA&gt;\n10              274918                               Kora    Skinner      &lt;NA&gt;\n11              650374                              Ridge   Chambers      &lt;NA&gt;\n12              418529                            Makayla       Wall      &lt;NA&gt;\n13              837256                              Issac      Trejo      &lt;NA&gt;\n14              104937                            Rosalyn       Huff      &lt;NA&gt;\n15              721584                            Finnley     Dillon      &lt;NA&gt;\n16              593860                             Laurel    Patrick      &lt;NA&gt;\n17              401753                            Derrick   Mitchell      &lt;NA&gt;\n18              682391                             Willow      Pitts      &lt;NA&gt;\n19              125784                               Trey     Mendez      &lt;NA&gt;\n20              879105                             Londyn      Eaton      &lt;NA&gt;\n21              536048                           Leighton       Shah      &lt;NA&gt;\n22              957230                           Angelica       Frye      &lt;NA&gt;\n23              301865                             Franco    Gardner      &lt;NA&gt;\n24              745921                             Jordyn   Delarosa      &lt;NA&gt;\n25              260173                             Osiris  Gallagher      &lt;NA&gt;\n26              884592                            Elliott       Beck      &lt;NA&gt;\n27              457309                            Eduardo     Grimes      &lt;NA&gt;\n28              608925                            Braelyn     Oliver      &lt;NA&gt;\n29              193746                             Karson     Graham      &lt;NA&gt;\n30              770283                              Alaia      Hardy      &lt;NA&gt;\n31              519467                            Jayceon     Santos      &lt;NA&gt;\n32              235801                              Alana Valenzuela      &lt;NA&gt;\n33              948236                             Jamari     Warren      &lt;NA&gt;\n34              461075                             Sloane    Cabrera      &lt;NA&gt;\n35              805329                               Cade     Rangel      &lt;NA&gt;\n36              672980                             Gloria    Pacheco      &lt;NA&gt;\n37              390147                               Erik       Duke      &lt;NA&gt;\n38    No. of Students:                                 30       &lt;NA&gt; Averages:\n39      Average Score:                   17.8333333333333       &lt;NA&gt;      &lt;NA&gt;\n40 Average Percentage:                               44.9       &lt;NA&gt;      &lt;NA&gt;\n41      Average Grade:                   4.65666666666667       &lt;NA&gt;      &lt;NA&gt;\n         Exam.Date:   45658        Batch.ID:     314159\n1              &lt;NA&gt;    &lt;NA&gt;             &lt;NA&gt;       &lt;NA&gt;\n2              &lt;NA&gt;    &lt;NA&gt;             &lt;NA&gt;       &lt;NA&gt;\n3              &lt;NA&gt;    &lt;NA&gt;             &lt;NA&gt;       &lt;NA&gt;\n4              &lt;NA&gt;    &lt;NA&gt;             &lt;NA&gt;       &lt;NA&gt;\n5              &lt;NA&gt;    &lt;NA&gt;             &lt;NA&gt;       &lt;NA&gt;\n6              &lt;NA&gt;    &lt;NA&gt;             &lt;NA&gt;       &lt;NA&gt;\n7             Grade Version            Score Percentage\n8               5.7       A               22         55\n9               3.4       A               13         33\n10              3.9       A               15         38\n11              5.5       A               21         53\n12              5.2       A               20         50\n13              3.4       A               13         33\n14                6       A               23         58\n15              4.2       B               16         40\n16              5.2       B               20         50\n17              5.7       B               22         55\n18              5.5       B               21         53\n19              3.7       B               14         35\n20                6       B               23         58\n21                5       B               19         48\n22              4.5       B               17         43\n23              3.9       B               15         38\n24              3.7       B               14         35\n25                6       C               23         58\n26              6.7       C               26         65\n27              3.4       C               13         33\n28              3.9       C               15         38\n29              4.7       C               18         45\n30              4.2       C               16         40\n31              6.4       D               25         63\n32                5       D               19         48\n33                5       D               19         48\n34              3.9       D               15         38\n35              2.6       D               10         25\n36              4.5       D               17         43\n37              2.9       D               11         28\n38 4.65666666666667    &lt;NA&gt; 17.8333333333333       44.9\n39             &lt;NA&gt;    &lt;NA&gt;             &lt;NA&gt;       &lt;NA&gt;\n40             &lt;NA&gt;    &lt;NA&gt;             &lt;NA&gt;       &lt;NA&gt;\n41             &lt;NA&gt;    &lt;NA&gt;             &lt;NA&gt;       &lt;NA&gt;\n\ncolnames(res2)\n\n[1] \"Program:\"                           \"Dept..Of.Underwater.Basket.Weaving\"\n[3] \"X3\"                                 \"X4\"                                \n[5] \"Exam.Date:\"                         \"45658\"                             \n[7] \"Batch.ID:\"                          \"314159\"                            \n\n\nThe extra metadata rows break the rectangular grid structure and interfere with our ability to access the individual exam results. Furthermore, the first row of metadata is interpreted as column names, which doesn’t make any sense in this case.\nFortunately, both read_excel() and read.xlsx() provide options for restricting the range of cells that we read. In the following code chunks, we use the range and rows arguments to read only the rectangular grid of individual exam results.\n\nres1 &lt;- read_excel(here::here(dataDir, \"example_data.xlsx\"),\n                   sheet = \"exam_results\",\n                   range = \"A10:H30\")\nres1\n\n# A tibble: 20 × 8\n       ID `First Name` `Last Name` ...4  Grade Version Score Percentage\n    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;       &lt;lgl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n 1 389472 Aniyah       Rojas       NA      5.7 A          22         55\n 2 915603 Colin        Logan       NA      3.4 A          13         33\n 3 274918 Kora         Skinner     NA      3.9 A          15         38\n 4 650374 Ridge        Chambers    NA      5.5 A          21         53\n 5 418529 Makayla      Wall        NA      5.2 A          20         50\n 6 837256 Issac        Trejo       NA      3.4 A          13         33\n 7 104937 Rosalyn      Huff        NA      6   A          23         58\n 8 721584 Finnley      Dillon      NA      4.2 B          16         40\n 9 593860 Laurel       Patrick     NA      5.2 B          20         50\n10 401753 Derrick      Mitchell    NA      5.7 B          22         55\n11 682391 Willow       Pitts       NA      5.5 B          21         53\n12 125784 Trey         Mendez      NA      3.7 B          14         35\n13 879105 Londyn       Eaton       NA      6   B          23         58\n14 536048 Leighton     Shah        NA      5   B          19         48\n15 957230 Angelica     Frye        NA      4.5 B          17         43\n16 301865 Franco       Gardner     NA      3.9 B          15         38\n17 745921 Jordyn       Delarosa    NA      3.7 B          14         35\n18 260173 Osiris       Gallagher   NA      6   C          23         58\n19 884592 Elliott      Beck        NA      6.7 C          26         65\n20 457309 Eduardo      Grimes      NA      3.4 C          13         33\n\ncolnames(res1)\n\n[1] \"ID\"         \"First Name\" \"Last Name\"  \"...4\"       \"Grade\"     \n[6] \"Version\"    \"Score\"      \"Percentage\"\n\nres2 &lt;- read.xlsx(here::here(dataDir, \"example_data.xlsx\"),\n                  sheet = \"exam_results\",\n                  rows = 10:40)\nres2\n\n       ID First.Name  Last.Name Grade Version Score Percentage\n1  389472     Aniyah      Rojas   5.7       A    22         55\n2  915603      Colin      Logan   3.4       A    13         33\n3  274918       Kora    Skinner   3.9       A    15         38\n4  650374      Ridge   Chambers   5.5       A    21         53\n5  418529    Makayla       Wall   5.2       A    20         50\n6  837256      Issac      Trejo   3.4       A    13         33\n7  104937    Rosalyn       Huff   6.0       A    23         58\n8  721584    Finnley     Dillon   4.2       B    16         40\n9  593860     Laurel    Patrick   5.2       B    20         50\n10 401753    Derrick   Mitchell   5.7       B    22         55\n11 682391     Willow      Pitts   5.5       B    21         53\n12 125784       Trey     Mendez   3.7       B    14         35\n13 879105     Londyn      Eaton   6.0       B    23         58\n14 536048   Leighton       Shah   5.0       B    19         48\n15 957230   Angelica       Frye   4.5       B    17         43\n16 301865     Franco    Gardner   3.9       B    15         38\n17 745921     Jordyn   Delarosa   3.7       B    14         35\n18 260173     Osiris  Gallagher   6.0       C    23         58\n19 884592    Elliott       Beck   6.7       C    26         65\n20 457309    Eduardo     Grimes   3.4       C    13         33\n21 608925    Braelyn     Oliver   3.9       C    15         38\n22 193746     Karson     Graham   4.7       C    18         45\n23 770283      Alaia      Hardy   4.2       C    16         40\n24 519467    Jayceon     Santos   6.4       D    25         63\n25 235801      Alana Valenzuela   5.0       D    19         48\n26 948236     Jamari     Warren   5.0       D    19         48\n27 461075     Sloane    Cabrera   3.9       D    15         38\n28 805329       Cade     Rangel   2.6       D    10         25\n29 672980     Gloria    Pacheco   4.5       D    17         43\n30 390147       Erik       Duke   2.9       D    11         28\n\ncolnames(res2)\n\n[1] \"ID\"         \"First.Name\" \"Last.Name\"  \"Grade\"      \"Version\"   \n[6] \"Score\"      \"Percentage\"\n\n\nThat’s better! Now, we have nice rectangular data frames containing only the interesting data.\n\n\n\n\n\n\nPractice\n\n\n\n\nUse the openxlsx::read.xlsx() function to load the first 100 rows (not counting column names) of the first 4 columns from the ‘diabetes’ sheet in the Excel workbook stored as “./data/example_data.xlsx”.\nUse the readxl::read_excel() function with an appropriate specification for the range argument to load the chunk of data beginning on Row 3 and Column 2 and ending on Row 100 and Column 7 from the ‘titanic’ sheet in “./data/example_data.xlsx”.\n\n\n Interactive Editor Directory Structure Solution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe following dendrogram illustrates the structure of the working directory for this webr session.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\ndiabetes &lt;- read.xlsx(here::here(\"data\", \"example_data.xlsx\"),\n                      sheet = \"diabetes\",\n                      rows = 1:101,\n                      cols = 1:4)\nhead(diabetes)\n\n  age  bmi  bp  tc\n1  59 32.1 101 157\n2  48 21.6  87 183\n3  72 30.5  93 156\n4  24 25.3  84 198\n5  50 23.0 101 192\n6  23 22.6  89 139\n\ntitanic3 &lt;- read_excel(here::here(\"data\", \"example_data.xlsx\"),\n                       sheet = \"titanic\",\n                       range = \"B3:G100\",\n                       col_names = FALSE)\nhead(titanic3)\n\n# A tibble: 6 × 6\n  ...1  ...2                                             ...3   ...4  ...5  ...6\n  &lt;chr&gt; &lt;chr&gt;                                            &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1st   Mrs. John Bradley (Florence Briggs Thayer) Cumi… fema…    38     1     0\n2 3rd   Miss. Laina Heikkinen                            fema…    26     0     0\n3 1st   Mrs. Jacques Heath (Lily May Peel) Futrelle      fema…    35     1     0\n4 3rd   Mr. William Henry Allen                          male     35     0     0\n5 3rd   Mr. James Moran                                  male     27     0     0\n6 1st   Mr. Timothy J McCarthy                           male     54     0     0\n\n\nNOTE: In the read_excel() call, we set col_names = FALSE to keep the function from converting the first row of data into column names.\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Excel Files"
    ]
  },
  {
    "objectID": "quizzes/saving/questions/write_txt.html",
    "href": "quizzes/saving/questions/write_txt.html",
    "title": "Question",
    "section": "",
    "text": "Question\nSave the data frame girls as a tab-delimited file, called girls.txt inside the folder “data”. Write the NA as empty space, and use the specific function. Assume that all the needed packages are already loaded.\n\n\nSolution\nThe specific function is write_tsv(), the file will be saved as \"data\\girls.txt\", and to save the NA as empty space we will need to specify na = \" \". So in the end, the expession will be: write_tsv(girls, \"data\\girls.txt\", na = \" \")\n\n\nMeta-information\nexname: Write .txt extype: string exsolution: write_tsv(girls, “data.txt”, na = ” “)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "quizzes/saving/index.html",
    "href": "quizzes/saving/index.html",
    "title": "Knowledge Quiz: Saving Data",
    "section": "",
    "text": "Note\n\n\n\n\nClick the check-mark button to check your answer.\nClick the question-mark button to see an explanation of the solution.\n\n\n\n\n\n\nSave the data frame girls as a tab-delimited file, called girls.txt inside the folder “data”. Write the NA as empty space, and use the specific function. Assume that all the needed packages are already loaded.\n\n\n\nThe specific function is write_tsv(), the file will be saved as \"data\\girls.txt\", and to save the NA as empty space we will need to specify na = \" \". So in the end, the expession will be: write_tsv(girls, \"data\\girls.txt\", na = \" \")\n\n\n\n\nWitch of the following expressions will save the data frame girls as a single R object and not a workspace file, and be sure to retain the object name. Assume that all the needed packages are already loaded.\n\nwrite_RDS(girls,  \"girls.rds\")It is not possible to save a R object as a .rds file while retaining its namewrite_RDS(girls, retain = TRUE, \"girls.rds\")write_sav(girls,  \"girls.sav\")save(girls,  \"girls.rds\")\n\n\n\nThe default value for the use argument is \"everything\".\n\nWrong: The function write_RDS doesn’t exist\nCorrect\nWrong: The function write_RDS doesn’t exist\nWrong: This will save the data frame as a .sav file, not an R object\nWrong: The function save() saves .RData files not .rds files\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "quizzes/loading/questions/loading_csv.html",
    "href": "quizzes/loading/questions/loading_csv.html",
    "title": "Question",
    "section": "",
    "text": "Question\nWe want to load the semicolon-separated file boys_eu in the directory data, so we use the function read_csv2(). Fill the void the code to get the tibble below:\nread_csv2( file = “data/boys_eu.csv”, col_select = -(6:8), col_types = cols( ____________________ ) )\n\n\n# A tibble: 6 × 6\n    age   hgt   wgt   bmi    hc reg  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;\n1 0.035  50.1  3.65  14.5  33.7 south\n2 0.038  53.5  3.37  11.8  35   south\n3 0.057  50    3.14  12.6  35.2 south\n4 0.06   54.5  4.27  14.4  36.7 south\n5 0.062  57.5  5.03  15.2  37.3 south\n6 0.068  55.5  4.66  15.1  37   south\n\n\n\n\nSolution\nWe have to specify that the variable reg is a factor variable, and we can do so using reg = col_factor()\n\n\nMeta-information\nexname: Loading CSV extype: string exsolution: reg = col_factor()\n\n\n\n\n Back to top"
  },
  {
    "objectID": "quizzes/loading/index.html",
    "href": "quizzes/loading/index.html",
    "title": "Knowledge Quiz: Loading Data",
    "section": "",
    "text": "Note\n\n\n\n\nClick the check-mark button to check your answer.\nClick the question-mark button to see an explanation of the solution.\n\n\n\n\n\n\nWhich of the following expressions will read the space-delimited file \"info.dat\"?\n\nAssume that all the necessary packages are already loaded.\nAssume the working directory has the following structure.\n\n\n\nread_delim(here::here(\"data\", \"info.dat\"), delim = \" \")read_delim(here::here(\"info.dat\"), delim = \" \")read_tsv(here::here(\"data\", \"info.dat\"), delim = \" \")read.table(here::here(\"data\", \"info.dat\"), header = TRUE, sep= \" \")read.table(here::here(\"data\", \"info.dat\"), header = TRUE)\n\n\n\n\nCORRECT: read_delim() is the correct tidyverse function. Here, we specify the space character as the delimiter.\nINCORRECT: The file path is wrong.\nINCORRECT: The function read_tsv() is for reading tab-delimited files.\nCORRECT: read.table() is the correct Base R function. Here, we specify the space character as the delimiter.\nCORRECT: read.table() is the correct Base R function.\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Knowledge Quiz"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "External Data",
    "section": "",
    "text": "Welcome to the External Data module. In this module you will learn how to use external datasets in your R analyses. We will first cover methods for loading datasets stored in the most common formats.",
    "crumbs": [
      "Open-Stat-Prog",
      "Overview"
    ]
  },
  {
    "objectID": "index.html#learning-goals",
    "href": "index.html#learning-goals",
    "title": "External Data",
    "section": "Learning Goals",
    "text": "Learning Goals\nAfter completing this module, you will be able to load data stored as:\n\nDelimited text files (e.g., tab-delimited, CSV)\nR’s native data files\nSPSS data files\nExcel workbooks",
    "crumbs": [
      "Open-Stat-Prog",
      "Overview"
    ]
  },
  {
    "objectID": "index.html#directory-structure",
    "href": "index.html#directory-structure",
    "title": "External Data",
    "section": "Directory Structure",
    "text": "Directory Structure\nThis module is all about reading data files from your computer’s hard drive. That focus presents a bit of a technical problem. The webr sessions in which you complete the exercises for these tutorials runs directly in your browser and cannot access your computer’s actual file system. So, we’ve created a synthetic directory structure for you to use in this module’s practice problems. The following dendrogram shows the contents of the working directory for the webr sessions that you’ll be using in this module. Note the data files stored in the ./data/ directory: those are the files we’ll be loading in this module.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nClick the button below to get started.\n\n\n Begin Tutorial",
    "crumbs": [
      "Open-Stat-Prog",
      "Overview"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "Now that you’ve completed the External Data module, you should be comfortable loading external datasets stored in various popular file formats.",
    "crumbs": [
      "Open-Stat-Prog",
      "Conclusion"
    ]
  },
  {
    "objectID": "conclusion.html#next-steps",
    "href": "conclusion.html#next-steps",
    "title": "Conclusion",
    "section": "Next Steps",
    "text": "Next Steps\nSince you’re now able to access real-world datasets in your R sessions, it’s time to start exploring methods for processing and manipulating those datasets. We recommend following the Data Manipulation module next. Click the button below to head over there now.\n\n\n Next Module",
    "crumbs": [
      "Open-Stat-Prog",
      "Conclusion"
    ]
  },
  {
    "objectID": "in_progress.html",
    "href": "in_progress.html",
    "title": "In Progress",
    "section": "",
    "text": "Sorry, we’re still building the page you’ve requested.\nIt’s almost done…really.\nWe’re just working through a few minor issues…\n\n\n\nImage Source"
  },
  {
    "objectID": "quizzes/loading/questions/delimited.html",
    "href": "quizzes/loading/questions/delimited.html",
    "title": "Question",
    "section": "",
    "text": "Which of the following expressions will read the space-delimited file \"info.dat\"?\n\nAssume that all the necessary packages are already loaded.\nAssume the working directory has the following structure.\n\n\n\n\n\nread_delim(\"data/info.dat\")\nread_delim(here::here(\"data\", \"info.dat\"), delim = \" \")\nread.table(here::here(\"data\", \"info.dat\"), header = TRUE, sep= \" \")\nread.table(here::here(\"data\", \"info.dat\"), header = TRUE)\nread_delim(here::here(\"data\", \"info.dat\"), delim = \"\\t\")\nread_delim(here::here(\"data\", \"info.dat\"), sep= \" \")\nread.table(here::here(\"data\", \"info.dat\"), sep= \"\\t\")\nread_tsv(here::here(\"data\", \"info.dat\"), delim = \" \")\nread_delim(here::here(\"info.dat\"))\nread_delim(here::here(\"info.dat\"), delim = \" \")\nread.table(here::here(\"info.dat\"), header = TRUE, sep= \" \")"
  },
  {
    "objectID": "quizzes/loading/questions/delimited.html#answerlist",
    "href": "quizzes/loading/questions/delimited.html#answerlist",
    "title": "Question",
    "section": "",
    "text": "read_delim(\"data/info.dat\")\nread_delim(here::here(\"data\", \"info.dat\"), delim = \" \")\nread.table(here::here(\"data\", \"info.dat\"), header = TRUE, sep= \" \")\nread.table(here::here(\"data\", \"info.dat\"), header = TRUE)\nread_delim(here::here(\"data\", \"info.dat\"), delim = \"\\t\")\nread_delim(here::here(\"data\", \"info.dat\"), sep= \" \")\nread.table(here::here(\"data\", \"info.dat\"), sep= \"\\t\")\nread_tsv(here::here(\"data\", \"info.dat\"), delim = \" \")\nread_delim(here::here(\"info.dat\"))\nread_delim(here::here(\"info.dat\"), delim = \" \")\nread.table(here::here(\"info.dat\"), header = TRUE, sep= \" \")"
  },
  {
    "objectID": "quizzes/loading/questions/delimited.html#answerlist-1",
    "href": "quizzes/loading/questions/delimited.html#answerlist-1",
    "title": "Question",
    "section": "Answerlist",
    "text": "Answerlist\n\nCORRECT: read_delim() is the correct tidyverse function. Here, we use suitable default options.\nCORRECT: read_delim() is the correct tidyverse function. Here, we specify the space character as the delimiter.\nCORRECT: read.table() is the correct Base R function. Here, we specify the space character as the delimiter.\nCORRECT: read.table() is the correct Base R function.\nINCORRECT: The delimiter is the space character, not the tab character.\nINCORRECT: To specify the delimiter in read_delim() the correct argument is delim, not sep.\nINCORRECT: The delimiter in the file is the space, not the tab.\nINCORRECT: The function read_tsv() is for reading tab-delimited files.\nINCORRECT: The file path is wrong.\nINCORRECT: The file path is wrong.\nINCORRECT: The file path is wrong."
  },
  {
    "objectID": "quizzes/loading/questions/spss_labels.html",
    "href": "quizzes/loading/questions/spss_labels.html",
    "title": "Question",
    "section": "",
    "text": "NOTE: BAD QUESTION. We can assign new value labels with val_label() and val_labels(), the syntax is just super confusing.\nConsider the following tibble. Which of the following expressions will remove the value labels from the hair_color column?\n\n\n\nstarwars$hair_color &lt;- unlabelled(starwars$hair_color)\nunlabelled(starwars$hair_color)\nval_label(starwars)$hair_color &lt;- NULL\nval_labels(starwars)$hair_color &lt;- NULL\nvar_labels(starwars)$hair_color &lt;- NULL\nval_labels(starwars$hair_color) &lt;- NULL\nunlabelled(starwars)$hair_color\nstarwars$hair_color &lt;- unlabelled(starwars)\nstarwars &lt;- unlabelled(starwars$hair_color)"
  },
  {
    "objectID": "quizzes/loading/questions/spss_labels.html#answerlist",
    "href": "quizzes/loading/questions/spss_labels.html#answerlist",
    "title": "Question",
    "section": "",
    "text": "starwars$hair_color &lt;- unlabelled(starwars$hair_color)\nunlabelled(starwars$hair_color)\nval_label(starwars)$hair_color &lt;- NULL\nval_labels(starwars)$hair_color &lt;- NULL\nvar_labels(starwars)$hair_color &lt;- NULL\nval_labels(starwars$hair_color) &lt;- NULL\nunlabelled(starwars)$hair_color\nstarwars$hair_color &lt;- unlabelled(starwars)\nstarwars &lt;- unlabelled(starwars$hair_color)"
  },
  {
    "objectID": "quizzes/loading/questions/spss_labels.html#answerlist-1",
    "href": "quizzes/loading/questions/spss_labels.html#answerlist-1",
    "title": "Question",
    "section": "Answerlist",
    "text": "Answerlist\n\nCorrect\nWrong: We do not want to remove all the labels\nWrong: val_label() is used to access the value labels for a variable, not to set those labels\nWrong: val_labels() is used to access the value labels, not to set labels\nWrong: var_labels() is used to get the list of variable labels, not to set labels\nWrong: val_labels() is used to get the list of value label, not to set labels\nWrong: This expression simply prints the hair_color vector from an entirely unlabeld version of starwars.\nWrong: This expression overwrites the hair_color column with the whole unlabeled data frame.\nWrong: This expression overwrites the entire data frame with the unlabelled hair_color vector."
  },
  {
    "objectID": "quizzes/saving/questions/save_rds.html",
    "href": "quizzes/saving/questions/save_rds.html",
    "title": "Question",
    "section": "",
    "text": "Witch of the following expressions will save the data frame girls as a single R object and not a workspace file, and be sure to retain the object name. Assume that all the needed packages are already loaded.\n\n\n\nIt is not possible to save a R object as a .rds file while retaining its name\nsaveRDS(girls,  \"girls.rds\")\nsaveRDS(girls, retain = TRUE, \"girls.rds\")\nsaveRDS(girls,  \"girls.RData\")\nsave(girls,  \"girls.RData\")\nsave(girls,  \"girls.rds\")\nwrite_RDS(girls,  \"girls.rds\")\nwrite_RDS(girls, retain = TRUE, \"girls.rds\")\nwrite_sav(girls,  \"girls.sav\")"
  },
  {
    "objectID": "quizzes/saving/questions/save_rds.html#answerlist",
    "href": "quizzes/saving/questions/save_rds.html#answerlist",
    "title": "Question",
    "section": "",
    "text": "It is not possible to save a R object as a .rds file while retaining its name\nsaveRDS(girls,  \"girls.rds\")\nsaveRDS(girls, retain = TRUE, \"girls.rds\")\nsaveRDS(girls,  \"girls.RData\")\nsave(girls,  \"girls.RData\")\nsave(girls,  \"girls.rds\")\nwrite_RDS(girls,  \"girls.rds\")\nwrite_RDS(girls, retain = TRUE, \"girls.rds\")\nwrite_sav(girls,  \"girls.sav\")"
  },
  {
    "objectID": "quizzes/saving/questions/save_rds.html#answerlist-1",
    "href": "quizzes/saving/questions/save_rds.html#answerlist-1",
    "title": "Question",
    "section": "Answerlist",
    "text": "Answerlist\n\nCorrect\nWrong: This will not save the name of the object\nWrong: The argument retain doesn’t exist\nWrong: The function saveRDS() saves .rds files, not .RData files\nWrong: This will save the data frame as workspace file\nWrong: The function save() saves .RData files not .rds files\nWrong: The function write_RDS doesn’t exist\nWrong: The function write_RDS doesn’t exist\nWrong: This will save the data frame as a .sav file, not an R object"
  },
  {
    "objectID": "tutorials/loading/delimited.html",
    "href": "tutorials/loading/delimited.html",
    "title": "Delimited Data",
    "section": "",
    "text": "Delimited text files are the simplest type of file that you’re likely to encounter when loading datasets into R. The files represent data as plain text where the data values are separated by a specific delimiter character: comma, tab, space.\nWhile base R provides functions for reading these kinds of files (e.g., read.table(), read.csv()), the readr package from the tidyverse provides a superior alternative. Relative to their Base R counterparts, the data-ingest functions in readr are faster, easier to configure, and more transparent in how they parse data.",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Delimited Data"
    ]
  },
  {
    "objectID": "tutorials/loading/delimited.html#space-delimited",
    "href": "tutorials/loading/delimited.html#space-delimited",
    "title": "Delimited Data",
    "section": "Space-Delimited",
    "text": "Space-Delimited\nWe’ll first consider space-delimited files wherein the data values are separated by a single white space character. We can use the readr::read_delim() function to load space-delimited files. When calling read_delim() we have two options for specifying the delimiter:\n\nLet the function detect the delimiter automatically (the default)\nSpecify the delimiter via the delim argument\n\n\nlibrary(readr)\n\n# Read the `boys.dat` file using default arguments and store the ingested values\n# in a data frame called 'boys'\nboys &lt;- read_delim(\"data/boys.dat\")\n\nRows: 748 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (3): gen, phb, reg\ndbl (6): age, hgt, wgt, bmi, hc, tv\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen we using read_delim() read a file, the function prints an informative message telling us about the delimiter and the data types that it detected/used. We should check this message to make sure the auto-detection worked correctly.\n\n# Check the result\nhead(boys)\n\n# A tibble: 6 × 9\n    age   hgt   wgt   bmi    hc gen   phb      tv reg  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n1 0.035  50.1  3.65  14.5  33.7 -999  -999   -999 south\n2 0.038  53.5  3.37  11.8  35   -999  -999   -999 south\n3 0.057  50    3.14  12.6  35.2 -999  -999   -999 south\n4 0.06   54.5  4.27  14.4  36.7 -999  -999   -999 south\n5 0.062  57.5  5.03  15.2  37.3 -999  -999   -999 south\n6 0.068  55.5  4.66  15.1  37   -999  -999   -999 south\n\n\nNotice that read_delim() returns a tibble and not an ordinary data frame. Tibbles are just slightly fancier flavor of data frame used by tidyverse packages. For our purposes, we can treat tibbles and data frames as equivalent objects.\n\n# Read the `boys.dat` file with the delimiter specifically defined\nboys &lt;- read_delim(\"data/boys.dat\", delim = \" \")\n\nRows: 748 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (3): gen, phb, reg\ndbl (6): age, hgt, wgt, bmi, hc, tv\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Check the result\nhead(boys)\n\n# A tibble: 6 × 9\n    age   hgt   wgt   bmi    hc gen   phb      tv reg  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n1 0.035  50.1  3.65  14.5  33.7 -999  -999   -999 south\n2 0.038  53.5  3.37  11.8  35   -999  -999   -999 south\n3 0.057  50    3.14  12.6  35.2 -999  -999   -999 south\n4 0.06   54.5  4.27  14.4  36.7 -999  -999   -999 south\n5 0.062  57.5  5.03  15.2  37.3 -999  -999   -999 south\n6 0.068  55.5  4.66  15.1  37   -999  -999   -999 south\n\n\n\nGood Path Habits\nIn the example above, we explicitly wrote out the path to the data file we wanted to read (i.e., \"data/boys.dat\"). That approach will work, but we can make our lives a lot easier by taking a few steps to improve the portability of our code. In the following code chunk, we make two important changes:\n\nCreate a variable called dataDir that contains the relative file path from the root directory of our project to the data folder.\nUse the here() function from the here package to resolve the file path.\n\n\nlibrary(here)\n\n\ndataDir &lt;- \"data\"\n\nboys &lt;- read_delim(here(\"data\", \"boys.dat\"))\n\nRows: 748 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (3): gen, phb, reg\ndbl (6): age, hgt, wgt, bmi, hc, tv\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(boys)\n\n# A tibble: 6 × 9\n    age   hgt   wgt   bmi    hc gen   phb      tv reg  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n1 0.035  50.1  3.65  14.5  33.7 -999  -999   -999 south\n2 0.038  53.5  3.37  11.8  35   -999  -999   -999 south\n3 0.057  50    3.14  12.6  35.2 -999  -999   -999 south\n4 0.06   54.5  4.27  14.4  36.7 -999  -999   -999 south\n5 0.062  57.5  5.03  15.2  37.3 -999  -999   -999 south\n6 0.068  55.5  4.66  15.1  37   -999  -999   -999 south",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Delimited Data"
    ]
  },
  {
    "objectID": "tutorials/loading/delimited.html#tab-delimited",
    "href": "tutorials/loading/delimited.html#tab-delimited",
    "title": "Delimited Data",
    "section": "Tab-Delimited",
    "text": "Tab-Delimited\nIn a tab-delimited file the data values are separated by tab characters (\\t). In the following code chunk, we load a file named diabetes.txt.\n\n# Let the function auto-detect the delimiter\ndiabetes &lt;- read_delim(here(dataDir, \"diabetes.txt\"))\n\nRows: 442 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): sex\ndbl (10): age, bmi, bp, tc, ldl, hdl, tch, ltg, glu, progress\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(diabetes)\n\n# A tibble: 6 × 11\n    age   bmi    bp    tc   ldl   hdl   tch   ltg   glu progress sex   \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; \n1    59  32.1   101   157  93.2    38     4  4.86    87      151 male  \n2    48  21.6    87   183 103.     70     3  3.89    69       75 female\n3    72  30.5    93   156  93.6    41     4  4.67    85      141 male  \n4    24  25.3    84   198 131.     40     5  4.89    89      206 female\n5    50  23     101   192 125.     52     4  4.29    80      135 female\n6    23  22.6    89   139  64.8    61     2  4.19    68       97 female\n\n# Manually explicate the delimiter\ndiabetes &lt;- read_delim(here(dataDir, \"diabetes.txt\"), delim = \"\\t\")\n\nRows: 442 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): sex\ndbl (10): age, bmi, bp, tc, ldl, hdl, tch, ltg, glu, progress\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(diabetes)\n\n# A tibble: 6 × 11\n    age   bmi    bp    tc   ldl   hdl   tch   ltg   glu progress sex   \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; \n1    59  32.1   101   157  93.2    38     4  4.86    87      151 male  \n2    48  21.6    87   183 103.     70     3  3.89    69       75 female\n3    72  30.5    93   156  93.6    41     4  4.67    85      141 male  \n4    24  25.3    84   198 131.     40     5  4.89    89      206 female\n5    50  23     101   192 125.     52     4  4.29    80      135 female\n6    23  22.6    89   139  64.8    61     2  4.19    68       97 female\n\n\nAlternatively, readr provides a dedicated function for reading tab-delimited files: read_tsv(). This function is just a wrapper around read_delim() with the delimiter preset to the tab character.\n\ndiabetes &lt;- read_tsv(here(dataDir, \"diabetes.txt\"))\n\nRows: 442 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (1): sex\ndbl (10): age, bmi, bp, tc, ldl, hdl, tch, ltg, glu, progress\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(diabetes)\n\n# A tibble: 6 × 11\n    age   bmi    bp    tc   ldl   hdl   tch   ltg   glu progress sex   \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; \n1    59  32.1   101   157  93.2    38     4  4.86    87      151 male  \n2    48  21.6    87   183 103.     70     3  3.89    69       75 female\n3    72  30.5    93   156  93.6    41     4  4.67    85      141 male  \n4    24  25.3    84   198 131.     40     5  4.89    89      206 female\n5    50  23     101   192 125.     52     4  4.29    80      135 female\n6    23  22.6    89   139  64.8    61     2  4.19    68       97 female\n\n\n\n\n\n\n\n\nPractice\n\n\n\nUse readr::read_delim() to load the data stored in the tab-delimited file “./data/iris.txt”.\n\n Interactive Editor Directory Structure Solution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe following dendrogram illustrates the structure of the working directory for this webr session.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\niris &lt;- read_delim(here::here(\"data\", \"iris.txt\"), delim = \"\\t\")\n\nRows: 150 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): Species\ndbl (5): ID, Sepal.Length, Sepal.Width, Petal.Length, Petal.Width\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(iris)\n\n# A tibble: 6 × 6\n     ID Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n  &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n1    43          5.1         3.5        -99           0.2 setosa \n2    44          4.9         3            1.4         0.2 setosa \n3    45          4.7         3.2          1.3         0.2 setosa \n4    46          4.6         3.1          1.5         0.2 setosa \n5    47          5           3.6        -99           0.2 setosa \n6    48        -99           3.9          1.7       -99   setosa",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Delimited Data"
    ]
  },
  {
    "objectID": "tutorials/loading/delimited.html#comma-separated-values",
    "href": "tutorials/loading/delimited.html#comma-separated-values",
    "title": "Delimited Data",
    "section": "Comma-Separated Values",
    "text": "Comma-Separated Values\nThe comma-separated values (CSV) format is one of the most popular delimited file types for storing tabular data. As the name implies, the data values are separated by commas. We can use the readr::read_delim() function with delim = \",\", but it’s more convenient to use the readr::read_csv() wrapper function.\n\nutmb &lt;- read_delim(here(dataDir, \"utmb_2017.csv\"), delim = \",\")\n\nNew names:\nRows: 2535 Columns: 33\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(6): name, team, category, nationality, time, timediff dbl (3): ...1, bib, rank\ntime (24): Delevret, St-Gervais, Contamines, La Balme, Bonhomme, Chapieux, C...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\nhead(utmb)\n\n# A tibble: 6 × 33\n   ...1   bib name      team  category  rank nationality time  timediff Delevret\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;time&gt;  \n1     0     4 D'HAENE … Salo… SE H         1 FR          19:0… 00:00:00 01:11:50\n2     1     2 JORNET B… Salo… SE H         2 ES          19:1… 00:15:05 01:10:00\n3     2    14 TOLLEFSO… Hoka  SE H         3 US          19:5… 00:51:06 01:15:24\n4     3     7 THEVENAR… Asics SE H         4 FR          20:0… 01:01:45 01:11:51\n5     4     1 WALMSLEY… Hoka  SE H         5 US          20:1… 01:09:44 01:09:59\n6     5    17 CAPELL P… The … SE H         6 ES          20:1… 01:10:49 01:13:16\n# ℹ 23 more variables: `St-Gervais` &lt;time&gt;, Contamines &lt;time&gt;,\n#   `La Balme` &lt;time&gt;, Bonhomme &lt;time&gt;, Chapieux &lt;time&gt;, `Col Seigne` &lt;time&gt;,\n#   `Lac Combal` &lt;time&gt;, `Mt-Favre` &lt;time&gt;, Checruit &lt;time&gt;, Courmayeur &lt;time&gt;,\n#   Bertone &lt;time&gt;, Bonatti &lt;time&gt;, Arnouvaz &lt;time&gt;, `Col Ferret` &lt;time&gt;,\n#   `La Fouly` &lt;time&gt;, `Champex La` &lt;time&gt;, `La Giète` &lt;time&gt;, Trient &lt;time&gt;,\n#   `Les Tseppe` &lt;time&gt;, Vallorcine &lt;time&gt;, `Col Montet` &lt;time&gt;,\n#   Flégère &lt;time&gt;, Arrivée &lt;time&gt;\n\nutmb &lt;- read_csv(here(dataDir, \"utmb_2017.csv\"))\n\nNew names:\nRows: 2535 Columns: 33\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(4): name, team, category, nationality dbl (3): ...1, bib, rank time (26):\ntime, timediff, Delevret, St-Gervais, Contamines, La Balme, Bonho...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\nhead(utmb)\n\n# A tibble: 6 × 33\n   ...1   bib name   team  category  rank nationality time     timediff Delevret\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;time&gt;   &lt;time&gt;   &lt;time&gt;  \n1     0     4 D'HAE… Salo… SE H         1 FR          19:01:54 00:00:00 01:11:50\n2     1     2 JORNE… Salo… SE H         2 ES          19:16:59 00:15:05 01:10:00\n3     2    14 TOLLE… Hoka  SE H         3 US          19:53:00 00:51:06 01:15:24\n4     3     7 THEVE… Asics SE H         4 FR          20:03:39 01:01:45 01:11:51\n5     4     1 WALMS… Hoka  SE H         5 US          20:11:38 01:09:44 01:09:59\n6     5    17 CAPEL… The … SE H         6 ES          20:12:43 01:10:49 01:13:16\n# ℹ 23 more variables: `St-Gervais` &lt;time&gt;, Contamines &lt;time&gt;,\n#   `La Balme` &lt;time&gt;, Bonhomme &lt;time&gt;, Chapieux &lt;time&gt;, `Col Seigne` &lt;time&gt;,\n#   `Lac Combal` &lt;time&gt;, `Mt-Favre` &lt;time&gt;, Checruit &lt;time&gt;, Courmayeur &lt;time&gt;,\n#   Bertone &lt;time&gt;, Bonatti &lt;time&gt;, Arnouvaz &lt;time&gt;, `Col Ferret` &lt;time&gt;,\n#   `La Fouly` &lt;time&gt;, `Champex La` &lt;time&gt;, `La Giète` &lt;time&gt;, Trient &lt;time&gt;,\n#   `Les Tseppe` &lt;time&gt;, Vallorcine &lt;time&gt;, `Col Montet` &lt;time&gt;,\n#   Flégère &lt;time&gt;, Arrivée &lt;time&gt;\n\n\n\nTrouble with Locales\nThe CSV format was developed in the United States where the period/full-stop character is used as the decimal separator. In countries that use the comma character to denote decimals (e.g., most European countries), it doesn’t make much sense to separate data fields with commas. In these countries, CSV files use semicolons as the delimiter (though the file type is still called comma-separated, unfortunately).\n\nboys &lt;- read_csv(here(dataDir, \"boys_eu.csv\"))\n\nRows: 748 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): age;hgt;wgt;bmi;hc;gen;phb;tv;reg\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(boys) # Oops...that doesn't look right\n\n# A tibble: 6 × 1\n  `age;hgt;wgt;bmi;hc;gen;phb;tv;reg` \n  &lt;chr&gt;                               \n1 0,035;50,1;3,650;14,54;33,7;;;;south\n2 0,038;53,5;3,370;11,77;35,0;;;;south\n3 0,057;50,0;3,140;12,56;35,2;;;;south\n4 0,060;54,5;4,270;14,37;36,7;;;;south\n5 0,062;57,5;5,030;15,21;37,3;;;;south\n6 0,068;55,5;4,655;15,11;37,0;;;;south\n\n\nTo read these type of EU-formatted CSV files, we can use the read_csv2() function.\n\nboys &lt;- read_csv2(here(dataDir, \"boys_eu.csv\"))\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 748 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (3): gen, phb, reg\ndbl (6): age, hgt, wgt, bmi, hc, tv\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(boys)\n\n# A tibble: 6 × 9\n    age   hgt   wgt   bmi    hc gen   phb      tv reg  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n1 0.035  50.1  3.65  14.5  33.7 &lt;NA&gt;  &lt;NA&gt;     NA south\n2 0.038  53.5  3.37  11.8  35   &lt;NA&gt;  &lt;NA&gt;     NA south\n3 0.057  50    3.14  12.6  35.2 &lt;NA&gt;  &lt;NA&gt;     NA south\n4 0.06   54.5  4.27  14.4  36.7 &lt;NA&gt;  &lt;NA&gt;     NA south\n5 0.062  57.5  5.03  15.2  37.3 &lt;NA&gt;  &lt;NA&gt;     NA south\n6 0.068  55.5  4.66  15.1  37   &lt;NA&gt;  &lt;NA&gt;     NA south",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Delimited Data"
    ]
  },
  {
    "objectID": "tutorials/loading/delimited.html#formatting-options",
    "href": "tutorials/loading/delimited.html#formatting-options",
    "title": "Delimited Data",
    "section": "Formatting Options",
    "text": "Formatting Options\nSome files contain known formatting issues that we’d like to correct as quickly as possible. The readr data-ingest functions contain many options that we can use to apply various formatting corrections when reading the data file.\n\nMissing Values\nIn many datasets, missing values are represented by placeholder codes, such as -999. We can instruct read_delim() to interpret such codes as NA by supply a vector of missing data codes for the na argument:\n\nboys &lt;- read_delim(here(dataDir, \"boys.dat\"), na = \"-999\")\n\nRows: 748 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (3): gen, phb, reg\ndbl (6): age, hgt, wgt, bmi, hc, tv\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(boys)\n\n# A tibble: 6 × 9\n    age   hgt   wgt   bmi    hc gen   phb      tv reg  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n1 0.035  50.1  3.65  14.5  33.7 &lt;NA&gt;  &lt;NA&gt;     NA south\n2 0.038  53.5  3.37  11.8  35   &lt;NA&gt;  &lt;NA&gt;     NA south\n3 0.057  50    3.14  12.6  35.2 &lt;NA&gt;  &lt;NA&gt;     NA south\n4 0.06   54.5  4.27  14.4  36.7 &lt;NA&gt;  &lt;NA&gt;     NA south\n5 0.062  57.5  5.03  15.2  37.3 &lt;NA&gt;  &lt;NA&gt;     NA south\n6 0.068  55.5  4.66  15.1  37   &lt;NA&gt;  &lt;NA&gt;     NA south\n\n\nNotice how all the “-999” values have been replaced by NA (R’s native missing data code). R will now correctly recognize these cells as missing values and treat them appropriately.\n\n\nSelecting Columns\nSome files contain columns that we really don’t care about and would rather just throw out immediately. For example, the first data column often contains an unnecessary row index. With readr, we can use the col_select argument to drop these columns directly when we read the data.\n\n# Drop the first column when reading the file\nutmb &lt;- read_csv(here(dataDir, \"utmb_2017.csv\"), col_select = -1)\n\nNew names:\nRows: 2535 Columns: 32\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(4): name, team, category, nationality dbl (2): bib, rank time (26): time,\ntimediff, Delevret, St-Gervais, Contamines, La Balme, Bonho...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\nhead(utmb)\n\n# A tibble: 6 × 32\n    bib name         team  category  rank nationality time     timediff Delevret\n  &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;time&gt;   &lt;time&gt;   &lt;time&gt;  \n1     4 D'HAENE Fra… Salo… SE H         1 FR          19:01:54 00:00:00 01:11:50\n2     2 JORNET BURG… Salo… SE H         2 ES          19:16:59 00:15:05 01:10:00\n3    14 TOLLEFSON T… Hoka  SE H         3 US          19:53:00 00:51:06 01:15:24\n4     7 THEVENARD X… Asics SE H         4 FR          20:03:39 01:01:45 01:11:51\n5     1 WALMSLEY Jim Hoka  SE H         5 US          20:11:38 01:09:44 01:09:59\n6    17 CAPELL Pau   The … SE H         6 ES          20:12:43 01:10:49 01:13:16\n# ℹ 23 more variables: `St-Gervais` &lt;time&gt;, Contamines &lt;time&gt;,\n#   `La Balme` &lt;time&gt;, Bonhomme &lt;time&gt;, Chapieux &lt;time&gt;, `Col Seigne` &lt;time&gt;,\n#   `Lac Combal` &lt;time&gt;, `Mt-Favre` &lt;time&gt;, Checruit &lt;time&gt;, Courmayeur &lt;time&gt;,\n#   Bertone &lt;time&gt;, Bonatti &lt;time&gt;, Arnouvaz &lt;time&gt;, `Col Ferret` &lt;time&gt;,\n#   `La Fouly` &lt;time&gt;, `Champex La` &lt;time&gt;, `La Giète` &lt;time&gt;, Trient &lt;time&gt;,\n#   `Les Tseppe` &lt;time&gt;, Vallorcine &lt;time&gt;, `Col Montet` &lt;time&gt;,\n#   Flégère &lt;time&gt;, Arrivée &lt;time&gt;\n\n\nThe col_select argument can do much more than we show in the above example. You can use any feature of the tidyselect selection language to include or exclude columns.\n\n\nColumn Data Types\nBy default, readr tries to guess the appropriate data type for each column based on the first 1,000 rows. We can use the spec() function to check how any readr data-ingest function parsed each column (i.e., which data types the function assigned).\n\nspec(utmb)\n\ncols(\n  ...1 = col_skip(),\n  bib = col_double(),\n  name = col_character(),\n  team = col_character(),\n  category = col_character(),\n  rank = col_double(),\n  nationality = col_character(),\n  time = col_time(format = \"\"),\n  timediff = col_time(format = \"\"),\n  Delevret = col_time(format = \"\"),\n  `St-Gervais` = col_time(format = \"\"),\n  Contamines = col_time(format = \"\"),\n  `La Balme` = col_time(format = \"\"),\n  Bonhomme = col_time(format = \"\"),\n  Chapieux = col_time(format = \"\"),\n  `Col Seigne` = col_time(format = \"\"),\n  `Lac Combal` = col_time(format = \"\"),\n  `Mt-Favre` = col_time(format = \"\"),\n  Checruit = col_time(format = \"\"),\n  Courmayeur = col_time(format = \"\"),\n  Bertone = col_time(format = \"\"),\n  Bonatti = col_time(format = \"\"),\n  Arnouvaz = col_time(format = \"\"),\n  `Col Ferret` = col_time(format = \"\"),\n  `La Fouly` = col_time(format = \"\"),\n  `Champex La` = col_time(format = \"\"),\n  `La Giète` = col_time(format = \"\"),\n  Trient = col_time(format = \"\"),\n  `Les Tseppe` = col_time(format = \"\"),\n  Vallorcine = col_time(format = \"\"),\n  `Col Montet` = col_time(format = \"\"),\n  Flégère = col_time(format = \"\"),\n  Arrivée = col_time(format = \"\")\n)\n\n\nWhile the auto-typing process is often correct, it’s not infallible. For more control, we can explicitly define column types using the col_types argument, which accepts a specification created using cols() and type constructors such as col_character(), col_integer(), and col_factor():\n\nutmb &lt;- read_csv(\n  file       = here(dataDir, \"utmb_2017.csv\"),\n  col_select = -1,\n  col_types  = cols(\n    bib         = col_character(),\n    category    = col_factor(),\n    rank        = col_integer(),\n    nationality = col_factor()\n  )\n)\n\nNew names:\n• `` -&gt; `...1`\n\nhead(utmb)\n\n# A tibble: 6 × 32\n  bib   name         team  category  rank nationality time     timediff Delevret\n  &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt; &lt;fct&gt;    &lt;int&gt; &lt;fct&gt;       &lt;time&gt;   &lt;time&gt;   &lt;time&gt;  \n1 4     D'HAENE Fra… Salo… SE H         1 FR          19:01:54 00:00:00 01:11:50\n2 2     JORNET BURG… Salo… SE H         2 ES          19:16:59 00:15:05 01:10:00\n3 14    TOLLEFSON T… Hoka  SE H         3 US          19:53:00 00:51:06 01:15:24\n4 7     THEVENARD X… Asics SE H         4 FR          20:03:39 01:01:45 01:11:51\n5 1     WALMSLEY Jim Hoka  SE H         5 US          20:11:38 01:09:44 01:09:59\n6 17    CAPELL Pau   The … SE H         6 ES          20:12:43 01:10:49 01:13:16\n# ℹ 23 more variables: `St-Gervais` &lt;time&gt;, Contamines &lt;time&gt;,\n#   `La Balme` &lt;time&gt;, Bonhomme &lt;time&gt;, Chapieux &lt;time&gt;, `Col Seigne` &lt;time&gt;,\n#   `Lac Combal` &lt;time&gt;, `Mt-Favre` &lt;time&gt;, Checruit &lt;time&gt;, Courmayeur &lt;time&gt;,\n#   Bertone &lt;time&gt;, Bonatti &lt;time&gt;, Arnouvaz &lt;time&gt;, `Col Ferret` &lt;time&gt;,\n#   `La Fouly` &lt;time&gt;, `Champex La` &lt;time&gt;, `La Giète` &lt;time&gt;, Trient &lt;time&gt;,\n#   `Les Tseppe` &lt;time&gt;, Vallorcine &lt;time&gt;, `Col Montet` &lt;time&gt;,\n#   Flégère &lt;time&gt;, Arrivée &lt;time&gt;\n\n# Check the data structure\nstr(utmb)\n\ntibble [2,535 × 32] (S3: tbl_df/tbl/data.frame)\n $ bib        : chr [1:2535] \"4\" \"2\" \"14\" \"7\" ...\n $ name       : chr [1:2535] \"D'HAENE François\" \"JORNET BURGADA Kilian\" \"TOLLEFSON Tim\" \"THEVENARD Xavier\" ...\n $ team       : chr [1:2535] \"Salomon\" \"Salomon\" \"Hoka\" \"Asics\" ...\n $ category   : Factor w/ 10 levels \"SE H\",\"V1 H\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ rank       : int [1:2535] 1 2 3 4 5 6 7 8 9 10 ...\n $ nationality: Factor w/ 66 levels \"FR\",\"ES\",\"US\",..: 1 2 3 1 3 2 3 4 3 2 ...\n $ time       : 'hms' num [1:2535] 19:01:54 19:16:59 19:53:00 20:03:39 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ timediff   : 'hms' num [1:2535] 00:00:00 00:15:05 00:51:06 01:01:45 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Delevret   : 'hms' num [1:2535] 01:11:50 01:10:00 01:15:24 01:11:51 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ St-Gervais : 'hms' num [1:2535] 01:45:05 01:44:21 01:48:38 01:45:08 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Contamines : 'hms' num [1:2535] 02:41:09 02:41:01 02:45:17 02:41:11 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ La Balme   : 'hms' num [1:2535] 03:33:40 03:33:45 03:41:50 03:33:45 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Bonhomme   : 'hms' num [1:2535] 04:28:07 04:29:18 04:41:04 04:38:06 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Chapieux   : 'hms' num [1:2535] 04:53:31 04:54:39 05:10:05 05:07:23 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Col Seigne : 'hms' num [1:2535] 06:18:02 06:18:04 06:40:51 06:41:10 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Lac Combal : 'hms' num [1:2535] 06:37:51 06:37:54 07:02:40 07:04:45 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Mt-Favre   : 'hms' num [1:2535] 07:15:35 07:15:37 07:42:45 07:45:38 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Checruit   : 'hms' num [1:2535] 07:39:09 07:39:16 08:08:05 08:11:11 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Courmayeur : 'hms' num [1:2535] 08:02:18 08:02:49 08:33:53 08:37:54 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Bertone    : 'hms' num [1:2535] 08:54:29 08:57:30 09:29:48 09:38:22 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Bonatti    : 'hms' num [1:2535] 09:44:00 09:48:28 10:21:27 10:31:58 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Arnouvaz   : 'hms' num [1:2535] 10:17:44 10:23:53 10:55:21 11:09:38 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Col Ferret : 'hms' num [1:2535] 11:11:12 11:18:54 NA 12:09:17 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ La Fouly   : 'hms' num [1:2535] 12:04:26 12:12:40 12:46:12 13:00:59 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Champex La : 'hms' num [1:2535] 13:24:20 13:33:52 14:08:23 14:22:44 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ La Giète   : 'hms' num [1:2535] 14:55:05 15:13:06 15:45:55 15:58:54 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Trient     : 'hms' num [1:2535] 15:24:59 15:41:22 16:12:00 16:28:53 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Les Tseppe : 'hms' num [1:2535] 16:06:17 16:23:16 16:56:16 17:12:35 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Vallorcine : 'hms' num [1:2535] 16:51:13 17:05:14 17:39:45 17:55:20 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Col Montet : 'hms' num [1:2535] 17:20:02 17:34:21 18:09:03 18:23:24 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Flégère    : 'hms' num [1:2535] 18:23:09 18:39:27 19:17:41 19:28:04 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n $ Arrivée    : 'hms' num [1:2535] 19:01:54 19:16:59 19:53:00 20:03:39 ...\n  ..- attr(*, \"units\")= chr \"secs\"\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ...1 = col_skip(),\n  ..   bib = col_character(),\n  ..   name = col_character(),\n  ..   team = col_character(),\n  ..   category = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),\n  ..   rank = col_integer(),\n  ..   nationality = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),\n  ..   time = col_time(format = \"\"),\n  ..   timediff = col_time(format = \"\"),\n  ..   Delevret = col_time(format = \"\"),\n  ..   `St-Gervais` = col_time(format = \"\"),\n  ..   Contamines = col_time(format = \"\"),\n  ..   `La Balme` = col_time(format = \"\"),\n  ..   Bonhomme = col_time(format = \"\"),\n  ..   Chapieux = col_time(format = \"\"),\n  ..   `Col Seigne` = col_time(format = \"\"),\n  ..   `Lac Combal` = col_time(format = \"\"),\n  ..   `Mt-Favre` = col_time(format = \"\"),\n  ..   Checruit = col_time(format = \"\"),\n  ..   Courmayeur = col_time(format = \"\"),\n  ..   Bertone = col_time(format = \"\"),\n  ..   Bonatti = col_time(format = \"\"),\n  ..   Arnouvaz = col_time(format = \"\"),\n  ..   `Col Ferret` = col_time(format = \"\"),\n  ..   `La Fouly` = col_time(format = \"\"),\n  ..   `Champex La` = col_time(format = \"\"),\n  ..   `La Giète` = col_time(format = \"\"),\n  ..   Trient = col_time(format = \"\"),\n  ..   `Les Tseppe` = col_time(format = \"\"),\n  ..   Vallorcine = col_time(format = \"\"),\n  ..   `Col Montet` = col_time(format = \"\"),\n  ..   Flégère = col_time(format = \"\"),\n  ..   Arrivée = col_time(format = \"\")\n  .. )\n\n\nWe can also use a compact string format, where each character represents the type of a column (e.g., \"d\" = double, \"f\" = factor).\n\nboys &lt;- read_csv2(here(dataDir, \"boys.csv\"), col_types = \"dddddffdf\")\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\nhead(boys)\n\n# A tibble: 6 × 9\n    age   hgt   wgt   bmi    hc gen   phb      tv reg  \n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt;\n1 0.035  50.1  3.65  14.5  33.7 &lt;NA&gt;  &lt;NA&gt;     NA south\n2 0.038  53.5  3.37  11.8  35   &lt;NA&gt;  &lt;NA&gt;     NA south\n3 0.057  50    3.14  12.6  35.2 &lt;NA&gt;  &lt;NA&gt;     NA south\n4 0.06   54.5  4.27  14.4  36.7 &lt;NA&gt;  &lt;NA&gt;     NA south\n5 0.062  57.5  5.03  15.2  37.3 &lt;NA&gt;  &lt;NA&gt;     NA south\n6 0.068  55.5  4.66  15.1  37   &lt;NA&gt;  &lt;NA&gt;     NA south\n\nstr(boys)\n\nspc_tbl_ [748 × 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ age: num [1:748] 0.035 0.038 0.057 0.06 0.062 0.068 0.068 0.071 0.071 0.073 ...\n $ hgt: num [1:748] 50.1 53.5 50 54.5 57.5 55.5 52.5 53 55.1 54.5 ...\n $ wgt: num [1:748] 3.65 3.37 3.14 4.27 5.03 ...\n $ bmi: num [1:748] 14.5 11.8 12.6 14.4 15.2 ...\n $ hc : num [1:748] 33.7 35 35.2 36.7 37.3 37 34.9 35.8 36.8 38 ...\n $ gen: Factor w/ 5 levels \"G1\",\"G2\",\"G3\",..: NA NA NA NA NA NA NA NA NA NA ...\n $ phb: Factor w/ 6 levels \"P1\",\"P2\",\"P3\",..: NA NA NA NA NA NA NA NA NA NA ...\n $ tv : num [1:748] NA NA NA NA NA NA NA NA NA NA ...\n $ reg: Factor w/ 5 levels \"south\",\"west\",..: 1 1 1 1 1 1 1 2 2 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   age = col_double(),\n  ..   hgt = col_double(),\n  ..   wgt = col_double(),\n  ..   bmi = col_double(),\n  ..   hc = col_double(),\n  ..   gen = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),\n  ..   phb = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),\n  ..   tv = col_double(),\n  ..   reg = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE)\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\n\n\n\nPractice\n\n\n\nUse readr::read_csv() to load the data stored in “./data/iris.csv”.\n\nFormat the Species column as a factor\nRemove the Petal.Width column while when reading the file.\nConvert “-88” and “-99” to missing values.\n\n\n Interactive Editor Directory Structure Solution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe following dendrogram illustrates the structure of the working directory for this webr session.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\niris &lt;- read_csv(here::here(\"data\", \"iris.csv\"),\n                 col_types = cols(Species = col_factor()),\n                 col_select = c(-ID, -Petal.Width),\n                 na = c(\"-88\", \"-99\"))\nhead(iris)\n\n# A tibble: 6 × 4\n  Sepal.Length Sepal.Width Petal.Length Species\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt; &lt;fct&gt;  \n1          5.1         3.5         NA   setosa \n2          4.9         3            1.4 setosa \n3          4.7         3.2          1.3 setosa \n4          4.6         3.1          1.5 setosa \n5          5           3.6         NA   setosa \n6         NA           3.9          1.7 setosa",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Delimited Data"
    ]
  },
  {
    "objectID": "tutorials/loading/delimited.html#base-r-options",
    "href": "tutorials/loading/delimited.html#base-r-options",
    "title": "Delimited Data",
    "section": "Base R Options",
    "text": "Base R Options\nBase R also includes built-in functions for reading delimited files. The Base R analogue of readr::read_delim() is read.table(). The read.table() function won’t attempt to auto-detect the delimiter, so we need to explicitly specify the delimiter character via the sep argument.\n\ndiabetes2 &lt;- read.table(here(dataDir, \"diabetes.txt\"),\n                        header = TRUE,\n                        sep = \"\\t\")\nhead(diabetes2)\n\n  age  bmi  bp  tc   ldl hdl tch    ltg glu progress    sex\n1  59 32.1 101 157  93.2  38   4 4.8598  87      151   male\n2  48 21.6  87 183 103.2  70   3 3.8918  69       75 female\n3  72 30.5  93 156  93.6  41   4 4.6728  85      141   male\n4  24 25.3  84 198 131.4  40   5 4.8903  89      206 female\n5  50 23.0 101 192 125.4  52   4 4.2905  80      135 female\n6  23 22.6  89 139  64.8  61   2 4.1897  68       97 female\n\n\nFor CSV files, the read.csv() and read.csv2() functions are wrappers around read.table() that will read US-formatted and EU-formatted CSV files.\n\n# Standard comma-separated CSV file\nutmb2 &lt;- read.csv(here(dataDir, \"utmb_2017.csv\"))\nhead(utmb2)\n\n  X bib                  name                  team category rank nationality\n1 0   4      D'HAENE François               Salomon     SE H    1          FR\n2 1   2 JORNET BURGADA Kilian               Salomon     SE H    2          ES\n3 2  14         TOLLEFSON Tim                  Hoka     SE H    3          US\n4 3   7      THEVENARD Xavier                 Asics     SE H    4          FR\n5 4   1          WALMSLEY Jim                  Hoka     SE H    5          US\n6 5  17            CAPELL Pau The North Face / Buff     SE H    6          ES\n      time timediff Delevret St.Gervais Contamines La.Balme Bonhomme Chapieux\n1 19:01:54 00:00:00 01:11:50   01:45:05   02:41:09 03:33:40 04:28:07 04:53:31\n2 19:16:59 00:15:05 01:10:00   01:44:21   02:41:01 03:33:45 04:29:18 04:54:39\n3 19:53:00 00:51:06 01:15:24   01:48:38   02:45:17 03:41:50 04:41:04 05:10:05\n4 20:03:39 01:01:45 01:11:51   01:45:08   02:41:11 03:33:45 04:38:06 05:07:23\n5 20:11:38 01:09:44 01:09:59   01:42:15   02:39:45 03:33:20 04:27:43 04:53:05\n6 20:12:43 01:10:49 01:13:16   01:46:46   02:43:57 03:37:13 04:35:55 05:04:53\n  Col.Seigne Lac.Combal Mt.Favre Checruit Courmayeur  Bertone  Bonatti Arnouvaz\n1   06:18:02   06:37:51 07:15:35 07:39:09   08:02:18 08:54:29 09:44:00 10:17:44\n2   06:18:04   06:37:54 07:15:37 07:39:16   08:02:49 08:57:30 09:48:28 10:23:53\n3   06:40:51   07:02:40 07:42:45 08:08:05   08:33:53 09:29:48 10:21:27 10:55:21\n4   06:41:10   07:04:45 07:45:38 08:11:11   08:37:54 09:38:22 10:31:58 11:09:38\n5   06:18:03   06:37:10 07:10:38 07:33:52   07:58:34 08:51:50 09:44:06 10:17:38\n6   06:34:38   06:55:57 07:37:29 08:00:59   08:25:08 09:24:11 10:19:34 10:57:51\n  Col.Ferret La.Fouly Champex.La La.Giète   Trient Les.Tseppe Vallorcine\n1   11:11:12 12:04:26   13:24:20 14:55:05 15:24:59   16:06:17   16:51:13\n2   11:18:54 12:12:40   13:33:52 15:13:06 15:41:22   16:23:16   17:05:14\n3            12:46:12   14:08:23 15:45:55 16:12:00   16:56:16   17:39:45\n4   12:09:17 13:00:59   14:22:44 15:58:54 16:28:53   17:12:35   17:55:20\n5   11:11:10 12:09:51   13:55:02 16:11:03 16:35:32   17:14:48   17:52:03\n6   12:01:54 12:59:54   14:22:45 15:58:47 16:28:31   17:12:38   17:57:23\n  Col.Montet  Flégère  Arrivée\n1   17:20:02 18:23:09 19:01:54\n2   17:34:21 18:39:27 19:16:59\n3   18:09:03 19:17:41 19:53:00\n4   18:23:24 19:28:04 20:03:39\n5   18:23:11 19:33:35 20:11:38\n6   18:28:03 19:39:00 20:12:43\n\n# CSV with semicolons as delimiters\nboys2 &lt;- read.csv2(here(dataDir, \"boys_eu.csv\"))\nhead(boys2)\n\n    age  hgt   wgt   bmi   hc gen phb tv   reg\n1 0.035 50.1 3.650 14.54 33.7         NA south\n2 0.038 53.5 3.370 11.77 35.0         NA south\n3 0.057 50.0 3.140 12.56 35.2         NA south\n4 0.060 54.5 4.270 14.37 36.7         NA south\n5 0.062 57.5 5.030 15.21 37.3         NA south\n6 0.068 55.5 4.655 15.11 37.0         NA south",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "Delimited Data"
    ]
  },
  {
    "objectID": "tutorials/loading/index.html",
    "href": "tutorials/loading/index.html",
    "title": "Loading Data",
    "section": "",
    "text": "Before we can do any data analysis, we need some data to analyze. So, one of the first steps in any real-world data analysis project will be loading/reading/ingesting data. In this tutorial, we explore methods for loading data stored in some of the most common file formats used for storing datasets:\n\nDelimited text\nR’s native data formats\nSPSS data files\nExcel workbooks\n\n\n\n\n Back to top",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data"
    ]
  },
  {
    "objectID": "tutorials/loading/spss_files.html",
    "href": "tutorials/loading/spss_files.html",
    "title": "SPSS Files",
    "section": "",
    "text": "Please enable JavaScript to experience the dynamic code cell content on this page.\nIn many research areas, especially the social and behavior sciences, datasets are stored and distributed using the native SPSS data format, SAV. So, there’s a reasonable chance that you’ll need to work with SAV files at some point in your data analytic career. Fortunately, the haven and labelled packages provide a powerful set of tools for working with data stored in SAV files.\nWe use the haven::read_spss() function to load data from SAV files.\n\nlibrary(haven)\n\ndataDir &lt;- \"data\"\n\nmtcars1 &lt;- read_spss(here::here(dataDir, \"mtcars.sav\"))\n\nSAV files contain some very useful metadata like variable labels (i.e., short description of a variable) and value labels (i.e., meaningful labels for the numeric levels of a variable). These metadata act as a built-in codebook for the dataset, so we’d really like to preserve this information when we read the data into R.\nFortunately, read_spss() preserves this information by representing numeric variables as labelled vectors. For example, when we print the am column in the following code chunk, you’ll notice several additional pieces of information printed alongside the variable’s actual values.\n\nmtcars1$am\n\n&lt;labelled&lt;double&gt;[32]&gt;: Transmission type\n [1] 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1\n\nLabels:\n value     label\n     0 Automatic\n     1    Manual\n\n\nLabelled vectors are very similar to factors: the underlying data values are stored as a numeric vector, and each unique numeric value is paired with a descriptive value label. Unlike factors, however, labelled vectors are meant to store numeric data. So, R will treat labelled vectors like numeric vectors for analysis.\n\n# R is happy to analyze labelled vectors as numeric data\nmean(mtcars1$am)\n\n[1] 0.40625\n\n# We can't do numeric calculations with factors\nam_factor &lt;- as.factor(mtcars$am)\nmean(am_factor)\n\nWarning in mean.default(am_factor): argument is not numeric or logical:\nreturning NA\n\n\n[1] NA\n\n\nWe can use the attributes() function to list all the attributes attached to the am column.\n\nattributes(mtcars1$am)\n\n$label\n[1] \"Transmission type\"\n\n$format.spss\n[1] \"F1.0\"\n\n$class\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\n$labels\nAutomatic    Manual \n        0         1 \n\n\nIn this case, we are most interested in the label and labels fields that show the variable label, and value labels, respectively.\n\nManipulating Labelled Vectors\nThe labelled package provides a suite of utilities for manipulating the metadata of labelled vectors, including the add, remove, or modify labels. We won’t cover these features in details here, but we’ll consider some of the basic options.\nWe may not care about the individual value labels. If so, we can remove the value labels (but retain the variable labels), with the labelled::unlabelled() function.\n\nlibrary(labelled)\n\nmtcars2 &lt;- unlabelled(mtcars1)\n\nIf we compare mtcars1 and mtcars2, we see that all the value labels are gone in mtcars2.\n\nval_labels(mtcars1)\n\n$mpg\nNULL\n\n$cyl\nNULL\n\n$disp\nNULL\n\n$hp\nNULL\n\n$drat\nNULL\n\n$wt\nNULL\n\n$qsec\nNULL\n\n$vs\nV-Shaped Straight \n       0        1 \n\n$am\nAutomatic    Manual \n        0         1 \n\n$gear\nNULL\n\n$carb\nNULL\n\nval_labels(mtcars2)\n\n$mpg\nNULL\n\n$cyl\nNULL\n\n$disp\nNULL\n\n$hp\nNULL\n\n$drat\nNULL\n\n$wt\nNULL\n\n$qsec\nNULL\n\n$vs\nNULL\n\n$am\nNULL\n\n$gear\nNULL\n\n$carb\nNULL\n\n\nThe variable labels are still present in both datasets, though.\n\nvar_label(mtcars1)\n\n$mpg\n[1] \"Fuel economy (miles/gallon)\"\n\n$cyl\n[1] \"Number of cylinders\"\n\n$disp\n[1] \"Displacement (cubic inches)\"\n\n$hp\n[1] \"Gross horsepower\"\n\n$drat\n[1] \"Rear axle ratio\"\n\n$wt\n[1] \"Weight (1000 pounds)\"\n\n$qsec\n[1] \"1/4 mile time (seconds)\"\n\n$vs\n[1] \"Cylinder geometry\"\n\n$am\n[1] \"Transmission type\"\n\n$gear\n[1] \"Number or forward gears\"\n\n$carb\n[1] \"Number or carburators\"\n\nvar_label(mtcars2)\n\n$mpg\n[1] \"Fuel economy (miles/gallon)\"\n\n$cyl\n[1] \"Number of cylinders\"\n\n$disp\n[1] \"Displacement (cubic inches)\"\n\n$hp\n[1] \"Gross horsepower\"\n\n$drat\n[1] \"Rear axle ratio\"\n\n$wt\n[1] \"Weight (1000 pounds)\"\n\n$qsec\n[1] \"1/4 mile time (seconds)\"\n\n$vs\n[1] \"Cylinder geometry\"\n\n$am\n[1] \"Transmission type\"\n\n$gear\n[1] \"Number or forward gears\"\n\n$carb\n[1] \"Number or carburators\"\n\n\n\n\n\n\n\n\nPractice\n\n\n\nUse the haven::read_spss() function to load the SPSS dataset saved as “./data/starwars.sav”.\n\nWhat is the variable label for the birth_year column?\nWhat are the value labels for the sex column?\n\n\n Interactive Editor Directory Structure Solution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe following dendrogram illustrates the structure of the working directory for this webr session.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nstarwars &lt;- read_spss(here::here(\"data\", \"starwars.sav\"))\nhead(starwars)\n\n# A tibble: 6 × 11\n  name   height  mass hair_color skin_color eye_color birth_year sex     gender \n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;  &lt;dbl+lbl&gt;      &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl+l&gt;\n1 Luke …    172    77  5 [blond]  7 [fair]   2 [blue]       19   3 [mal… 2 [mas…\n2 C-3PO     167    75 NA          9 [gold]  15 [yell…      112   4 [non… 2 [mas…\n3 R2-D2      96    32 NA         29 [white… 11 [red]        33   4 [non… 2 [mas…\n4 Darth…    202   136 10 [none]  28 [white] 15 [yell…       41.9 3 [mal… 2 [mas…\n5 Leia …    150    49  7 [brown] 17 [light]  4 [brow…       19   1 [fem… 1 [fem…\n6 Owen …    178   120  8 [brown… 17 [light]  2 [blue]       52   3 [mal… 2 [mas…\n# ℹ 2 more variables: homeworld &lt;dbl+lbl&gt;, species &lt;dbl+lbl&gt;\n\n\nVariable label for birth_year:\n\nvar_label(starwars$birth_year)\n\n[1] \"Year of birth (BBY = Before Battle of Yavin)\"\n\n\nValue labels for sex:\n\nval_labels(starwars$sex)\n\n        female hermaphroditic           male           none \n             1              2              3              4 \n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Open-Stat-Prog",
      "Loading Data",
      "SPSS Files"
    ]
  },
  {
    "objectID": "tutorials/saving/topic1.html",
    "href": "tutorials/saving/topic1.html",
    "title": "First Topic",
    "section": "",
    "text": "Etiam non efficitur urna, quis elementum nisi. Mauris posuere a augue vel gravida. Praesent luctus erat et ex iaculis interdum. Nulla vestibulum quam ac nunc consequat vulputate. Nullam iaculis lobortis sem sit amet fringilla. Aliquam semper, metus ut blandit semper, nulla velit fermentum sapien, fermentum ultrices dolor sapien sed leo. Vestibulum molestie faucibus magna, at feugiat nulla ullamcorper a. Aliquam erat volutpat. Praesent scelerisque magna a justo maximus, sit amet suscipit mauris tempor. Nulla nec dolor eget ipsum pellentesque lobortis a in ipsum. Morbi turpis turpis, fringilla a eleifend maximus, viverra nec neque. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos."
  },
  {
    "objectID": "tutorials/saving/topic1.html#blah",
    "href": "tutorials/saving/topic1.html#blah",
    "title": "First Topic",
    "section": "Blah",
    "text": "Blah\nMaecenas turpis velit, ultricies non elementum vel, luctus nec nunc. Nulla a diam interdum, faucibus sapien viverra, finibus metus. Donec non tortor diam. In ut elit aliquet, bibendum sem et, aliquam tortor. Donec congue, sem at rhoncus ultrices, nunc augue cursus erat, quis porttitor mauris libero ut ex. Nullam quis leo urna. Donec faucibus ligula eget pellentesque interdum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean rhoncus interdum erat ut ultricies. Aenean tempus ex non elit suscipit, quis dignissim enim efficitur. Proin laoreet enim massa, vitae laoreet nulla mollis quis.\nVestibulum ultrices, tortor at mattis porta, odio nisi rutrum nulla, sit amet tincidunt eros quam facilisis tellus. Fusce eleifend lectus in elementum lacinia. Nam auctor nunc in massa ullamcorper, sit amet auctor ante accumsan. Nam ut varius metus. Curabitur eget tristique leo. Cras finibus euismod erat eget elementum. Integer vel placerat ex. Ut id eros quis lectus lacinia venenatis hendrerit vel ante."
  }
]